# Configuration pour l'environnement local
# URL de base pour Ollama (utiliser le nom du service Docker)
OLLAMA_BASE_URL=http://ollama:11434

# Configuration OpenWebUI
WEBUI_NAME=OpenWebUI Local
WEBUI_AUTH=True
ENABLE_SIGNUP=True
DEFAULT_USER_ROLE=user

# Configuration réseau
OPENWEBUI_PORT=8080
OLLAMA_PORT=11434

# Configuration des uploads
MAX_UPLOAD_SIZE=25000000

# Configuration du partage communautaire (désactivé en local)
ENABLE_COMMUNITY_SHARING=False

# Configuration des modèles
ENABLE_MODEL_FILTER=False
MODEL_FILTER_LIST=

# Configuration de sécurité
WEBUI_SECRET_KEY=your-secret-key-here-change-in-production

# Configuration des logs
LOG_LEVEL=INFO
